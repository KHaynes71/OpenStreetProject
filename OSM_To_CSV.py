{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# ## Audit The Data\n",
    "# \n",
    "# In this section we will iterate over the street names and zip codes. We will check for uniformity in the data against an expected dictionary of values.\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "import csv\n",
    "import cerberus\n",
    "import schema\n",
    "import codecs\n",
    "\n",
    "osm_file = open(\"Houston_Texas.osm\", \"r\")\n",
    "\n",
    "#\n",
    "\n",
    "#########################################\n",
    "\n",
    "# Search for all unexpected street types\n",
    "\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "\n",
    "\n",
    "# List of expected street name values\n",
    "expected = [\"Street\", \"Avenue\", \"Lane\", \"Way\", \"Boulevard\",  \n",
    "\"Drive\", \"Court\", \"Place\", \"Square\", \"Road\", \"Trail\", \"Parkway\", \"Commons\", \"North\", \"South\", \"West\", \"East\"]\n",
    "\n",
    "# Here we add any street name that isn't in our expected dictionary\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "    return street_types\n",
    "\n",
    "# Here we create a dictionary of our postal codes\n",
    "def audit_postal_code(postal_code_types, postal_code):  \n",
    "    if not postal_code.isupper() or ' ' not in postal_code:\n",
    "        postal_code_types['case_whitespace_problems'].add(postal_code)\n",
    "    else:\n",
    "        postal_code_types['other'].add(postal_code)\n",
    "    return postal_code_types\n",
    "\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def is_postal_code(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "#audit(osm_file)\n",
    "#print_sorted_dict(street_types)\n",
    "\n",
    "def audit(filename):\n",
    "    f = (filename)\n",
    "    street_types = defaultdict(set)\n",
    "    postal_code_types = defaultdict(set)\n",
    "    \n",
    "    for event, element in ET.iterparse(f, events=(\"start\",)):\n",
    "        if element.tag == \"node\" or element.tag ==\"way\":\n",
    "            for tag in element.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "                if is_postal_code(tag):\n",
    "                    audit_postal_code(postal_code_types, tag.attrib['v'])\n",
    "                    \n",
    "    f.close()\n",
    "    return dict(street_types), dict(postal_code_types)\n",
    "\n",
    "\n",
    "# After the audits we found that street names were very inconsistent. Often mixing abreviations with full spellings of words like \"street\" vs \"st.\", Postal codes were also problematic. Mixing 5 digit postal codes and 10 digit postal codes. Some even contained the state abbreviation within in them ex: 33709FL \n",
    "\n",
    "# ## Fixing Street Names and Postal Codes\n",
    "# \n",
    "# Having observed inconsistencies within the street name and zip code data we will create cleaning functions that will update the street names and zip codes according to a mapping standard.\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ave\" : \"Avenue\",\n",
    "            \"Ave.\": \"Avenue\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Rd\": \"Road\",\n",
    "            \"E\" : \"East\",\n",
    "            \"W\" : \"West\",\n",
    "            \"S\" : \"South\",\n",
    "            \"N\" : \"North\"\n",
    "            }\n",
    "\n",
    "# Here we iterate over each name and compare/update it in regards to our selected mapping\n",
    "def update_name(street_name, mapping):\n",
    "    street_name = street_name.replace(' ', ' ')\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        street_type2 = ' '.join(street_name.split()[0:])\n",
    "        if street_type in mapping.keys():\n",
    "            #print 'Before: ' , name\n",
    "            street_name = re.sub(street_type, mapping[street_type],street_name)\n",
    "            #print 'After: ', name\n",
    "        \n",
    "    return street_name\n",
    "\n",
    "# Here we iterate over the postal codes making them a uniform 5 digit number\n",
    "def update_postal_code(postal_code):\n",
    "    postal_code = postal_code.upper()\n",
    "    if ' ' not in postal_code:\n",
    "        if len(postal_code) != 5:\n",
    "            postal_code = postal_code[0:5]\n",
    "    return postal_code\n",
    "\n",
    "\n",
    "def street_test():\n",
    "    \n",
    "    st_types = audit(osm_file)[0]\n",
    "    print (\"\")\n",
    "    for st_types, st_names in st_types.iteritems():\n",
    "        for name in st_names:\n",
    "            better_name = update_name(name, mapping)\n",
    "            print (name, \"->\", better_name)\n",
    "            \n",
    "def postal_code_test():\n",
    "    postcode_types = audit(osm_file)[1]\n",
    "    #pprint(postcode_types)\n",
    "    print (\"\")\n",
    "    \n",
    "    for postcode_type, postcodes in postcode_types.iteritems():\n",
    "        for postcode in postcodes:\n",
    "            better_postcode = update_postal_code(postcode)\n",
    "            print (postcode, \"=>\", better_postcode)\n",
    "        \n",
    "\n",
    "\n",
    "# ## OSM To CSV\n",
    "# Here we will take the osm file and shape them into a CSV file\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "OSM_PATH = \"Houston_Texas.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+\\/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "\n",
    "# The function 'make_tag_dict()' takes an element and a child tag, and then creates a dictionary with keys 'id', 'key', 'value', 'type'\n",
    "# according to the rules specified in the problem\n",
    "\n",
    "def make_tag_dict(element, tag):\n",
    "    tag_attribs = {}                           \n",
    "    tag_attribs['id'] = element.attrib['id']\n",
    "    \n",
    "    if is_street_name(tag):\n",
    "        tag_attribs['value'] = update_street_name(tag.attrib['v'], mapping, mapping2)  \n",
    "    elif is_postal_code(tag):\n",
    "        tag_attribs['value'] = update_postal_code(tag.attrib['v'])              # update street names and postal codes\n",
    "                                                                                \n",
    "    else:\n",
    "        tag_attribs['value'] = tag.attrib['v']\n",
    "    \n",
    "    k_attrib = tag.attrib['k']\n",
    "    if not PROBLEMCHARS.search(k_attrib):\n",
    "        if LOWER_COLON.search(k_attrib):        # If the 'k_attrib' string contains a ':' character, then set \n",
    "            key = k_attrib.split(':', 1)[1]     # tag_attribs['key'] to be everything after the first colon,\n",
    "            tipe = k_attrib.split(':', 1)[0]    # and tag_attribs['type'] to be everything before the first colon\n",
    "            tag_attribs['key'] = key\n",
    "            tag_attribs['type'] = tipe\n",
    "        else:\n",
    "            tag_attribs['key'] = k_attrib\n",
    "            tag_attribs['type'] = 'regular'\n",
    "        \n",
    "    return tag_attribs\n",
    "\n",
    "\n",
    "def shape_element(element):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "    if element.tag == 'node':\n",
    "        for item in NODE_FIELDS:                      # Populate the 'node_attribs' dict with the keys from NODE_FIELDS\n",
    "            node_attribs[item] = element.attrib[item] # and the values from the 'element.attrib' dictionary\n",
    "        for tag in element.iter('tag'):\n",
    "            if tag.attrib['v'] == \"\" or tag.attrib['v'] == None:\n",
    "                continue\n",
    "            tag_attribs = make_tag_dict(element, tag) # Call the function make_tag_dict() that creates a dictionary of\n",
    "            tags.append(tag_attribs)                  # tag attributes.  Then append this dict to the 'tags' list.\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    \n",
    "    elif element.tag == 'way':\n",
    "        for item in WAY_FIELDS:                       # Populate the 'way_attribs' dict with the keys from WAY_FIELDS\n",
    "            way_attribs[item] = element.attrib[item]  # and the values from the 'element.attrib' dict\n",
    "        for tag in element.iter('tag'):\n",
    "            if tag.attrib['v'] == \"\" or tag.attrib['v'] == None:\n",
    "                continue\n",
    "            tag_attribs = make_tag_dict(element, tag) # Again use the function make_tag_dict() to create a dictionary \n",
    "            tags.append(tag_attribs)                  # of tag attributes\n",
    "            \n",
    "        position = 0\n",
    "        for tag in element.iter('nd'):\n",
    "            nd_attribs = {}                           # Initialize and populate the 'nd_attribs' dictionary according\n",
    "            nd_attribs['id'] = element.attrib['id']   # to the rules specified in the problem\n",
    "            nd_attribs['node_id'] = tag.attrib['ref']\n",
    "            nd_attribs['position'] = position\n",
    "            position += 1\n",
    "            way_nodes.append(nd_attribs)\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "    \n",
    "\n",
    "# ================================================== #\n",
    "#              Other Helper Functions                #\n",
    "# ================================================== #\n",
    "\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_strings = (\n",
    "            \"{0}: {1}\".format(k, v if isinstance(v, str) else \", \".join(v))\n",
    "            for k, v in errors.iteritems()\n",
    "        )\n",
    "        raise cerberus.ValidationError(\n",
    "            message_string.format(field, \"\\n\".join(error_strings))\n",
    "        )\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, bytes) else v) for k, v in row.items()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "\n",
    "\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file,          codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file,          codecs.open(WAYS_PATH, 'w') as ways_file,          codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file,          codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "                    \n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
